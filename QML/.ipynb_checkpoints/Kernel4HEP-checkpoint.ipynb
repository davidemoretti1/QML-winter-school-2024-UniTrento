{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f95095ea-0c64-4cc0-97b1-8959fa13c943",
   "metadata": {},
   "source": [
    "\n",
    "### Installing Qiskit 1.2.X\n",
    "\n",
    "Anaconda or a pyenv is recommended to manage all dependencies. \n",
    "The file environment.yml contains the required libraries and can be installed in this way:\n",
    "\n",
    "Command: `conda env create -f environment.yml`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42017dc-c548-4050-a6df-2fd65fac1cbc",
   "metadata": {},
   "source": [
    "# Binary Classification with Qiskit\n",
    "## Introduction to (Q)kernel methods\n",
    "\n",
    "Quantum Machine Learning (QML) leverages quantum properties to enhance classical ML techniques. \n",
    "QSVM (Quantum Support Vector Machine) is a quantum analog of SVM, ideal for classification tasks. \n",
    "\n",
    "In this tutorial, we apply QSVM to a High Energy Physics (HEP) dataset for binary classification, reproducing results from the literature.\n",
    "[See the paper](https://iopscience.iop.org/article/10.1088/2632-2153/ad5fdd)\n",
    "\n",
    "## Dataset\n",
    "The dataset focuses on signal $t\\bar  t H(b\\bar b) $ and background QCD events. Each event is characterized by 67 features derived from physics objects like jets, leptons, and MET. Key variables include:\n",
    "\n",
    "- $p_T$ (transverse momentum)\n",
    "- $\\epsilon$ (pseudorapidity)\n",
    "- $\\phi$ (azimuthal angle)\n",
    "\n",
    "Preselection and event criteria ensure data suitability for ML tasks. [Source dataset info](https://qml-hep.github.io/qml_web/data/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e6d1d2-e8bc-4420-86e5-bc2136fa47c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Libraries (already present in the env file)\n",
    "#!pip install qiskit qiskit-machine-learning matplotlib pandas scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6bee60-658a-4c9d-9b4b-9f49cdaea653",
   "metadata": {},
   "source": [
    "### Dataset extracted from the paper\n",
    "The dataset used in this tutorial represents the result of the AutoEncoder compression applied to the whole 67 features.\n",
    "If you want to reproduce the full pipeline and use the same setting of the paper, see the [repository](https://github.com/CERN-IT-INNOVATION/gqc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8669d8fb-8529-4969-8c66-d8e6eff65ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Classification with QSVM in Qiskit\n",
    "\n",
    "## Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import time\n",
    "\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit.visualization import circuit_drawer\n",
    "from qiskit.primitives import Sampler\n",
    "from qiskit_machine_learning.state_fidelities import ComputeUncompute\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "\n",
    "# Load the dataset\n",
    "bkg = np.load(\"bkg.npy\")\n",
    "sig = np.load(\"sig.npy\")\n",
    "\n",
    "# Combine the data into X (features) and y (labels)\n",
    "X = np.vstack((bkg, sig))\n",
    "y = np.hstack((np.zeros(bkg.shape[0]), np.ones(sig.shape[0])))\n",
    "\n",
    "# Map labels to \"Background\" and \"Signal\"\n",
    "label_mapping = {0: \"Background\", 1: \"Signal\"}\n",
    "y_named = np.vectorize(label_mapping.get)(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c373f85-5386-4b1f-8b10-a488432090f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset info: dimensionality, class balance\n",
    "print(f\"Dataset loaded with {X.shape[0]} samples and {X.shape[1]} features.\")\n",
    "print(f\"Number of background samples: {bkg.shape[0]}\")\n",
    "print(f\"Number of signal samples: {sig.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f16ac7-7141-46a1-ba6b-1276a9e524f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a DataFrame for easier exploration\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "feature_names = [f\"Feature_{i+1}\" for i in range(X.shape[1])]\n",
    "data = pd.DataFrame(X, columns=feature_names)\n",
    "data['Label'] = y\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "data[feature_names] = scaler.fit_transform(data[feature_names])\n",
    "\n",
    "# Map labels to \"Background\" and \"Signal\"\n",
    "label_mapping = {0: \"Background\", 1: \"Signal\"}\n",
    "data['Label'] = data['Label'].map(label_mapping)\n",
    "\n",
    "# Display dataset info\n",
    "print(\"Dataset overview after normalization:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac4435f-9f93-4d45-91e8-9ba1e56134ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dataset size for testing (the smaller the faster runtime)\n",
    "max_samples = 200\n",
    "data = data.sample(n=max_samples, random_state=42)\n",
    "X = data[feature_names].values\n",
    "y_named = data['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3508b10c-e1ea-41cc-9ec6-3759ba1e67cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data exploration\n",
    "\n",
    "# Plot distribution of features for signal vs background\n",
    "for feature in feature_names:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(data, x=feature, hue='Label', kde=True, stat='density', common_norm=False)\n",
    "    plt.title(f\"Distribution of {feature}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d85ddf5-ca63-45dd-a251-cdfca9b77219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "correlation_matrix = data.drop(columns=['Label']).corr()\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Feature Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992efd22-4a4f-4274-979a-35e459f92597",
   "metadata": {},
   "source": [
    "## Feature selection: Mutual Information\n",
    "\n",
    "Mutual Information (MI) measures the dependency between variables. \n",
    "\n",
    "It quantifies how much knowing one variable reduces the uncertainty of another. \n",
    "\n",
    "Mathematically, MI between two variables X and Y is:\n",
    "\n",
    "$MI(X, Y) = âˆ‘ P(x, y) * log(P(x, y) / (P(x) * P(y)))$\n",
    "\n",
    "where P(x, y) is the joint probability of X and Y, and P(x), P(y) are their marginals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad439fc-c933-4fef-8d4b-4c0e40a9aae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mutual information\n",
    "mi_scores = mutual_info_classif(X, (y_named == \"Signal\").astype(int), discrete_features=False)\n",
    "mi_scores_df = pd.DataFrame({'Feature': feature_names, 'MI Score': mi_scores})\n",
    "mi_scores_df = mi_scores_df.sort_values(by='MI Score', ascending=False)\n",
    "\n",
    "# Plot mutual information scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='MI Score', y='Feature', data=mi_scores_df, palette=\"viridis\")\n",
    "plt.title(\"Mutual Information Scores\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b953dc6-1eac-40ba-8188-43d7e9a6ce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top N features (e.g., top 5)\n",
    "top_features = mi_scores_df['Feature'].head(2).values\n",
    "X_selected = data[top_features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b22cdf0-d082-4486-9a96-443af5556a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## QSVM Classification\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, (y_named == \"Signal\").astype(int), test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the quantum kernel with a ZZFeatureMap\n",
    "feature_map = ZZFeatureMap(feature_dimension=X_selected.shape[1], reps=2, entanglement=\"linear\")\n",
    "\n",
    "# Visualize the quantum feature map\n",
    "print(\"Quantum feature map circuit:\")\n",
    "feature_map.decompose().draw(output='mpl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94359b2-c4a1-4fd9-a27b-127ad764168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the sizes of training and testing sets\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Testing set size: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0700c5-a025-493f-949e-28db603fcd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the fidelity and kernel\n",
    "sampler = Sampler()\n",
    "fidelity = ComputeUncompute(sampler=sampler)\n",
    "quantum_kernel = FidelityQuantumKernel(fidelity=fidelity, feature_map=feature_map)\n",
    "\n",
    "# Train and evaluate the QSVM\n",
    "train_features = X_train\n",
    "test_features = X_test\n",
    "train_labels = y_train\n",
    "test_labels = y_test\n",
    "\n",
    "adhoc_svc = SVC(kernel=quantum_kernel.evaluate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde1db38-262e-4568-952b-66501e124637",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training QSVM...\")\n",
    "start_time = time.time()\n",
    "adhoc_svc.fit(train_features, train_labels)\n",
    "training_time = time.time() - start_time\n",
    "print(f\"QSVM training completed in {training_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca2574c-086a-41ae-ad21-89d420519ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the QSVM\n",
    "adhoc_score = adhoc_svc.score(test_features, test_labels)\n",
    "y_pred = adhoc_svc.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8867671-4ce9-454b-af08-b40f76a888f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"QSVM Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(test_labels, y_pred))\n",
    "print(classification_report(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96276da6-adb4-4b79-9733-805e7be685ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### A closer look into the kernel\n",
    "adhoc_matrix_train = quantum_kernel.evaluate(x_vec=train_features)\n",
    "adhoc_matrix_test = quantum_kernel.evaluate(x_vec=test_features, y_vec=train_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd98177e-c922-4304-b3ff-070d76791283",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].imshow(\n",
    "    np.asmatrix(adhoc_matrix_train), interpolation=\"nearest\", origin=\"upper\", cmap=\"Blues\"\n",
    ")\n",
    "axs[0].set_title(\"Ad hoc training kernel matrix\")\n",
    "\n",
    "axs[1].imshow(np.asmatrix(adhoc_matrix_test), interpolation=\"nearest\", origin=\"upper\", cmap=\"Reds\")\n",
    "axs[1].set_title(\"Ad hoc testing kernel matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbf93bf-4a24-4533-8fea-d0cb9b5e27b2",
   "metadata": {},
   "source": [
    "A good training kernel matrix should exhibit the following properties:\n",
    "\n",
    "- Clear Block Diagonal Patterns: Samples from the same class should have high similarity, forming visible blocks of high values.\n",
    "- Low Cross-Class Similarity: Off-diagonal blocks (different class comparisons) should show low similarity.\n",
    "- Numerical Stability: The values should not be excessively skewed (e.g., not all close to 0 or 1).\n",
    "- Proper Normalization: Quantum kernels often scale inputs, ensuring values are meaningful for classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdea6028-140c-435d-bd2c-28f454109f63",
   "metadata": {},
   "source": [
    "### Let's do some benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed26855-cec3-49eb-985b-3069749888b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classical SVM for benchmarking\n",
    "\n",
    "print(\"Training classical SVM for comparison...\")\n",
    "start_time = time.time()\n",
    "classical_svc = SVC(kernel='linear')\n",
    "classical_svc.fit(train_features, train_labels)\n",
    "classical_training_time = time.time() - start_time\n",
    "print(f\"Classical SVM training completed in {classical_training_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c4615d-3d04-4da0-9130-7872de42467c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the classical SVM\n",
    "classical_score = classical_svc.score(test_features, test_labels)\n",
    "y_pred_classical = classical_svc.predict(test_features)\n",
    "\n",
    "print(\"Classical SVM Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(test_labels, y_pred_classical))\n",
    "print(classification_report(test_labels, y_pred_classical))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec809b56-2e9b-40ed-904c-8624622b11cb",
   "metadata": {},
   "source": [
    "### Beyond kernels\n",
    "Next we show how a `SamplerQNN` can be used for classification within a `NeuralNetworkClassifier`. In this context, the SamplerQNN is expected to return n-dimensional probability vector as output, in our binary example is 2. The underlying Sampler primitive returns quasi-distributions of bit strings and we just need to define a mapping from the measured bitstrings to the different classes. For binary classification we use the ***parity mapping***. \n",
    "We can use the `QNNCircuit` class to set up a parameterized quantum (PQC) circuit from a feature map and ansatz of our choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0df7832-c4c5-431f-8dff-d0420543ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit.library import TwoLocal\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
    "from qiskit_machine_learning.algorithms import NeuralNetworkClassifier\n",
    "\n",
    "# Define a feature map and ansatz for the quantum neural network\n",
    "feature_map = ZZFeatureMap(feature_dimension=X_selected.shape[1], reps=2, entanglement=\"linear\")\n",
    "ansatz = TwoLocal(X_selected.shape[1], ['ry', 'rz'], 'cz', reps=2, entanglement=\"full\")\n",
    "\n",
    "ansatz.draw(\"mpl\", style=\"clifford\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc117e2-edf9-4e88-9829-913dca016bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the feature map and ansatz into a quantum circuit\n",
    "qc = feature_map.compose(ansatz)\n",
    "print(\"Quantum Circuit for SamplerQNN:\")\n",
    "qc.decompose().draw(output='mpl')\n",
    "plt.show()\n",
    "\n",
    "# Create a SamplerQNN\n",
    "sampler = Sampler()\n",
    "sampler_qnn = SamplerQNN(circuit=qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, sampler=sampler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6893d536-c370-4416-9a0e-8c4619b515ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_machine_learning.optimizers import COBYLA, L_BFGS_B\n",
    "# Create a NeuralNetworkClassifier\n",
    "classifier = NeuralNetworkClassifier(neural_network=sampler_qnn, optimizer=COBYLA(maxiter=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a531dd0d-029e-4015-a802-9a2c77f8af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier\n",
    "print(\"Training SamplerQNN classifier...\")\n",
    "start_time = time.time()\n",
    "classifier.fit(X_train, y_train)\n",
    "training_time_qnn = time.time() - start_time\n",
    "print(f\"SamplerQNN training completed in {training_time_qnn:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efc1329-568b-4302-ae7d-5fbf2fedfc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the classifier\n",
    "y_pred_qnn = classifier.predict(X_test)\n",
    "print(\"SamplerQNN Classifier Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_qnn))\n",
    "print(classification_report(y_test, y_pred_qnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369ea858-6b7d-497c-87d7-ed3824ebc6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
